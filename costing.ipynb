{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b034d-6fd3-4a79-98b4-e0d428f87692",
   "metadata": {},
   "source": [
    "# Cleaning costing data\n",
    "### date 6/7/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3ce03bc-7fe3-4812-8b90-cda1130e2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eea08761-69f7-4dce-a440-40973f426e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_raw = pd.read_csv(\"../qualtrics_survey/SITT-MAT Weekly Implementation Activity Survey for SITT-MAT Team_June 10, 2024_11.39.csv\")\n",
    "# remove first two rows\n",
    "df_raw = df_raw.iloc[2:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa8eea-2172-4b18-bdd4-64b420b7c141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6d04f20-3c51-4956-88d1-f8a6e07ad5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract time and convert to hours\n",
    "def extract_hours(task):\n",
    "    minutes = re.findall(r'(\\d+)\\s*min', task)\n",
    "    if minutes:\n",
    "        return int(minutes[0]) / 60\n",
    "    hours = re.findall(r'(\\d+)\\s*hour', task)\n",
    "    if hours:\n",
    "        return int(hours[0])\n",
    "    other_minutes = re.findall(r'(\\d+)\\s*minutes', task)\n",
    "    if other_minutes:\n",
    "        return int(other_minutes[0]) / 60\n",
    "    return 0\n",
    "\n",
    "# Function to check if the \"Notes\" column contains minutes\n",
    "def contains_minutes(notes):\n",
    "    return bool(re.search(r'\\d+\\s*(min|minutes)', notes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41e5704c-54c6-4b6b-8cea-653e42816c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    rename_dict = {\n",
    "    'Q1': 'Name',\n",
    "    'Q2': 'Start Date',\n",
    "    'Q3': 'End Date',\n",
    "    'Q6_1_1': 'EMF_meetings_mins',\n",
    "    'Q6_1_2': 'EMF_meetings_notes',\n",
    "    'Q6_2_1': 'EMF_datacollection_mins',\n",
    "    'Q6_2_2': 'EMF_datacollection_notes',\n",
    "    'Q6_3_1': 'EMF_REDCap_mins',\n",
    "    'Q6_3_2': 'EMF_REDCap_notes',\n",
    "    'Q6_4_1': 'EMF_dashboard_mins',\n",
    "    'Q6_4_2': 'EMF_dashboard_notes',\n",
    "    'Q6_5_1': 'EMF_reporttemplate_mins',\n",
    "    'Q6_5_2': 'EMF_reporttemplate_notes',\n",
    "    'Q6_6_1': 'EMF_IMATcalculations_mins',\n",
    "    'Q6_6_2': 'EMF_IMATcalculations_notes',\n",
    "    'Q6_7_1': 'EMF_datawebinar_prep_mins',\n",
    "    'Q6_7_2': 'EMF_datawebinar_prep_notes',\n",
    "    'Q6_8_1': 'EMF_datawebinar_invite_mins',\n",
    "    'Q6_8_2': 'EMF_datawebinar_invite_notes',\n",
    "    'Q6_9_1': 'EMF_datawebinar_host_mins',\n",
    "    'Q6_9_2': 'EMF_datawebinar_host_notes',\n",
    "    'Q6_10_1': 'EMF_datainquiries_mins',\n",
    "    'Q6_10_2': 'EMF_datainquiries_notes',\n",
    "    'Q6_11_1': 'EMF_ServiceRegistry_inforequest_mins',\n",
    "    'Q6_11_2': 'EMF_ServiceRegistry_inforequest_notes',\n",
    "    'Q6_12_1': 'EMF_ServiceRegistry_validation_mins',\n",
    "    'Q6_12_2': 'EMF_ServiceRegistry_validation_notes',\n",
    "    'Q6_13_1': 'EMF_ServiceRegistry_analysis_mins',\n",
    "    'Q6_13_2': 'EMF_ServiceRegistry_analysis_notes',\n",
    "    'Q6_14_1': 'EMF_generatereport_mins',\n",
    "    'Q6_14_2': 'EMF_generatereport_notes',\n",
    "    'Q6_15_1': 'EMF_returnreport_mins',\n",
    "    'Q6_15_2': 'EMF_returnreport_notes',\n",
    "    'Q7_1_1': 'NIATxMAT_meetings_mins',\n",
    "    'Q7_1_2': 'NIATxMAT_meetings_notes',\n",
    "    'Q7_2_1': 'NIATxMAT_academyplan_mins',\n",
    "    'Q7_2_2': 'NIATxMAT_academyplan_notes',\n",
    "    'Q7_3_1': 'NIATxMAT_academyinvites_mins',\n",
    "    'Q7_3_2': 'NIATxMAT_academyinvites_notes',\n",
    "    'Q7_4_1': 'NIATxMAT_academyparticipation_mins',\n",
    "    'Q7_4_2': 'NIATxMAT_academyparticipation_notes',\n",
    "    'Q8_1_1': 'InternalF_meetings_mins',\n",
    "    'Q8_1_2': 'InternalF_meetings_notes',\n",
    "    'Q8_2_1': 'InternalF_content_mins',\n",
    "    'Q8_2_2': 'InternalF_content_notes',\n",
    "    'Q8_3_1': 'InternalF_datacollection_mins',\n",
    "    'Q8_3_2': 'InternalF_datacollection_notes',\n",
    "    'Q8_4_1': 'InternalF_invites_mins',\n",
    "    'Q8_4_2': 'InternalF_invites_notes',\n",
    "    'Q8_5_1': 'InternalF_identifiedchangeleader_mins',\n",
    "    'Q8_5_2': 'InternalF_identifiedchangeleader_notes',\n",
    "    'Q8_6_1': 'InternalF_trackedsiteparticipation_mins',\n",
    "    'Q8_6_2': 'InternalF_trackedsiteparticipation_notes',\n",
    "    'Q8_7_1': 'InternalF_ledcoachcalls_mins',\n",
    "    'Q8_7_2': 'InternalF_ledcoachcalls_notes',\n",
    "    'Q8_8_1': 'InternalF_additionalsupport_mins',\n",
    "    'Q8_8_2': 'InternalF_additionalsupport_notes',\n",
    "    'Q9_1_1': 'ExternalF_meetings_mins',\n",
    "    'Q9_1_2': 'ExternalF_meetings_notes',\n",
    "    'Q9_2_1': 'ExternalF_content_mins',\n",
    "    'Q9_2_2': 'ExternalF_content_notes',\n",
    "    'Q9_3_1': 'ExternalF_datasystems_mins',\n",
    "    'Q9_3_2': 'ExternalF_datasystems_notes',\n",
    "    'Q9_4_1': 'ExternalF_participantinvites_mins',\n",
    "    'Q9_4_2': 'ExternalF_participantinvites_notes',\n",
    "    'Q9_5_1': 'ExternalF_trackedsiteparticipation_mins',\n",
    "    'Q9_5_2': 'ExternalF_trackedsiteparticipation_notes',\n",
    "    'Q9_6_1': 'ExternalF_plannedcoachcalls_mins',\n",
    "    'Q9_6_2': 'ExternalF_plannedcoachcalls_notes',\n",
    "    'Q9_7_1': 'ExternalF_ledcoachcalls_mins',\n",
    "    'Q9_7_2': 'ExternalF_ledcoachcalls_notes',\n",
    "    'Q9_8_1': 'ExternalF_additionalsupport_mins',\n",
    "    'Q9_8_2': 'ExternalF_additionalsupport_notes',\n",
    "    'Q44_Id': 'ExternalF_coachtrackerid',\n",
    "    'Q44_Name': 'ExternalF_coachtrackername',\n",
    "    'Q44_Size': 'ExternalF_coachtrackersize',\n",
    "    'Q44_Type': 'ExternalF_coachtrackertype',\n",
    "    'Q10_1_1': 'SIC/COINS_meetings_mins',\n",
    "    'Q10_1_2': 'SIC/COINS_meetings_notes',\n",
    "    'Q10_2_1': 'SIC/COINS_content_mins',\n",
    "    'Q10_2_2': 'SIC/COINS_content_notes',\n",
    "    'Q10_3_1': 'SIC/COINS_trackedinfo_mins',\n",
    "    'Q10_3_2': 'SIC/COINS_trackedinfo_notes',\n",
    "    'Q10_4_1': 'SIC/COINS_fidelityscale_mins',\n",
    "    'Q10_4_2': 'SIC/COINS_fidelityscale_notes',\n",
    "    'Q10_5_1': 'SIC/COINS_sustainementscale_mins',\n",
    "    'Q10_5_2': 'SIC/COINS_sustainementscale_notes',\n",
    "    'Q10_6_1': 'SIC/COINS_developedtracker_mins',\n",
    "    'Q10_6_2': 'SIC/COINS_developedtracker_notes',\n",
    "    'Q10_7_1': 'SIC/COINS_validation_mins',\n",
    "    'Q10_7_2': 'SIC/COINS_validation_notes',\n",
    "    'Q10_8_1': 'SIC/COINS_data_mins',\n",
    "    'Q10_8_2': 'SIC/COINS_data_notes',\n",
    "    'Q11_1_1': 'SITMAATTeam_meetings_mins',\n",
    "    'Q11_1_2': 'SITMAATTeam_meetings_notes',\n",
    "    'Q11_2_1': 'SITMAATTeam_costsurvey_mins',\n",
    "    'Q11_2_2': 'SITMAATTeam_costsurvey_notes',\n",
    "    'Q11_3_1': 'SITMAATTeam_validatecostsurvey_mins',\n",
    "    'Q11_3_2': 'SITMAATTeam_validatecostsurvey_notes',\n",
    "    'Q11_4_1': 'SITMAATTeam_costdata_mins',\n",
    "    'Q11_4_2': 'SITMAATTeam_costdata_notes',\n",
    "    'Q12_1': 'additionalactivity_notes1',\n",
    "    'Q12_2': 'additionalactivity_notes2',\n",
    "    'Q12_3': 'additionalactivity_notes3',\n",
    "    'Q12_4': 'additionalactivity_notes4',\n",
    "    'Q12_5': 'additionalactivity_notes5',\n",
    "    'Q13': 'additionalcosting_notes'\n",
    "}\n",
    "     # Identify extra columns\n",
    "    extra_columns = [col for col in df.columns if col not in rename_dict]\n",
    "    if extra_columns:\n",
    "        print(f\"Warning: The following columns are not renamed and will be dropped: {extra_columns}\")\n",
    "    \n",
    "\n",
    "    return df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba9225a6-642d-4162-aec8-edcc1fe51bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_additional_activities(df_raw):\n",
    "    # Goal: name, start date, end date, category, activity details, mins, hrs\n",
    "    sittmaat_weekex = df_raw\n",
    "    sittmaat_weekex = rename_columns(sittmaat_weekex)\n",
    "\n",
    "    # Subset df without metadata (first 2 rows) and only questions related to \"not involved in SITTMAT\"\n",
    "    sittmaat_weekex = sittmaat_weekex[[\"Name\", \"Start Date\", \"End Date\", \"additionalactivity_notes1\", \"additionalactivity_notes2\", \"additionalactivity_notes3\",\n",
    "                                      \"additionalactivity_notes4\", \"additionalactivity_notes5\", \"additionalcosting_notes\"]]\n",
    "\n",
    "    # Renaming columns\n",
    "    sittmaat_weekex.columns = [\n",
    "        \"Name\", \"Start Date\", \"End Date\", \"Additionalactivity1_notes\", \"Additionalactivity2_notes\", \n",
    "        \"Additionalactivity3_notes\", \"Additionalactivity4_notes\", \"Additionalactivity5_notes\", \"Additionalcosting_notes\"\n",
    "    ]\n",
    "\n",
    "    # Wide to long form (Category/Activity/EstMin)\n",
    "    sittmaat_weekex = pd.melt(sittmaat_weekex, id_vars=[\"Name\", \"Start Date\", \"End Date\"], \n",
    "                              var_name=\"Activity\", value_name=\"Notes\")\n",
    "\n",
    "    # Omit NA rows\n",
    "    sittmaat_weekex = sittmaat_weekex.dropna(subset=['Notes'])\n",
    "\n",
    "    # Add activity category column\n",
    "    sittmaat_weekex['Category'] = sittmaat_weekex['Activity'].apply(lambda x: \"Additional Activities\" if x.startswith(\"Additionalactivity\") else \"Additional Costing\" if x.startswith(\"Additionalcosting\") else None)\n",
    "\n",
    "    # Remove Activity column\n",
    "    sittmaat_cleaned = sittmaat_weekex.drop(columns=[\"Activity\"])\n",
    "    \n",
    "    # Split into hours and no hours based on the presence of minutes in the \"Notes\" column\n",
    "    sittmaat_cleaned_hours = sittmaat_cleaned[sittmaat_cleaned['Notes'].apply(contains_minutes)]\n",
    "    sittmaat_cleaned_no_hours = sittmaat_cleaned[~sittmaat_cleaned['Notes'].apply(contains_minutes)]\n",
    "\n",
    "    # Get the hours from the minutes indicated\n",
    "    sittmaat_cleaned_hours.insert(4, 'hours', sittmaat_cleaned_hours['Notes'].apply(extract_hours))\n",
    "\n",
    "    return sittmaat_cleaned_hours, sittmaat_cleaned_no_hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae744518-1ee4-46eb-a6cc-5645e5f9ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_not_involved(df_raw):\n",
    "    # Subset the dataframe where Q4 equals the specific string\n",
    "    sittmaat_weekex = df_raw[df_raw['Q4'] == \"No (Note: selecting this will take you to the end of survey)\"]\n",
    "    # Subset with only specific columns\n",
    "    sittmaat_not_involved = sittmaat_weekex[['Q1', 'Q2', 'Q3']]\n",
    "\n",
    "    # Renaming columns\n",
    "    sittmaat_not_involved.columns = [\"Name\", \"Start Date\", \"End Date\"]\n",
    "    return sittmaat_not_involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4394021e-9511-4164-85ce-ff2477c82ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_optional_notes(df_raw):\n",
    "    # Filter the dataframe where Q4 equals \"Yes\"\n",
    "    sittmaat_weekex = df_raw[df_raw['Q4'] == \"Yes\"]\n",
    "\n",
    "    # Drop the initial metadata columns (first 17 columns)\n",
    "    sittmaat_weekex = sittmaat_weekex.drop(columns=sittmaat_weekex.columns[:17])\n",
    "\n",
    "    # Drop the fourth column (index 3 after the above operations)\n",
    "    sittmaat_weekex = sittmaat_weekex.drop(columns=['Q4'])\n",
    "    \n",
    "    #rename columns\n",
    "    sittmaat_weekex = rename_columns(sittmaat_weekex)\n",
    "\n",
    "    \n",
    "    # pivot longer\n",
    "    sittmaat_weekex = sittmaat_weekex.melt(id_vars=[\"Name\", \"Start Date\", \"End Date\"], \n",
    "                                           value_vars=[col for col in sittmaat_weekex.columns if col.endswith('_mins') or col.endswith('_notes')],\n",
    "                                           var_name=\"Activity\", value_name=\"Notes\")\n",
    "\n",
    "\n",
    "    sittmaat_weekex[['Activity', 'ValueType']] = sittmaat_weekex['Activity'].str.extract(r'(.+)_([a-z]+)')\n",
    "    sittmaat_weekex = sittmaat_weekex.drop_duplicates()\n",
    "    sittmaat_weekex = sittmaat_weekex.pivot(index=['Name', \"Start Date\", \"End Date\", 'Activity'], \n",
    "                                            columns='ValueType', values='Notes').reset_index()\n",
    "\n",
    "    # rename new columns\n",
    "    sittmaat_weekex = sittmaat_weekex.rename(columns={\n",
    "        'mins': 'Mins',\n",
    "        'notes': 'Optional Notes'\n",
    "    })\n",
    "    \n",
    "    # Omit NA rows\n",
    "    sittmaat_weekex = sittmaat_weekex.dropna(subset=['Mins'])\n",
    "\n",
    "    # Convert mins to numeric and create hours\n",
    "    sittmaat_weekex['Mins'] = pd.to_numeric(sittmaat_weekex['Mins'])\n",
    "    sittmaat_weekex['Hrs'] = sittmaat_weekex['Mins'] / 60\n",
    "\n",
    "    # Add activity category column\n",
    "    sittmaat_weekex['Category'] = sittmaat_weekex['Activity'].apply(lambda x: \n",
    "        \"EMF\" if x.startswith(\"EMF_\") else \n",
    "        \"NIATxMAT Academy\" if x.startswith(\"NIATxMAT_\") else \n",
    "        \"Internal Facilitation\" if x.startswith(\"InternalF_\") else \n",
    "        \"External Facilitation\" if x.startswith(\"ExternalF_\") else \n",
    "        \"SIC/COINS\" if x.startswith(\"SIC/COINS_\") else \n",
    "        \"SITMAAT Purveyor Team\" if x.startswith(\"SITMAATTeam_\") else \n",
    "        \"Additional Relevant Activities\" if x.startswith(\"additionalactivity\") else \n",
    "        \"Additional Costing Tasks\" if x.startswith(\"additionalcosting_\") else \n",
    "        None\n",
    "    )\n",
    "    \n",
    "    sittmaat_weekex = sittmaat_weekex.reset_index(drop=True)\n",
    "    return sittmaat_weekex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ab66fc5-ccdf-4e04-b0ce-0816d6389371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_involved(df_raw):\n",
    "    raw_sittmaat_weekex = df_raw\n",
    "    # Drop metadata and the first two rows\n",
    "    sittmaat_weekex = raw_sittmaat_weekex.drop(columns=raw_sittmaat_weekex.columns[:17])\n",
    "    # Subset data where Q4 == \"Yes\"\n",
    "    sittmaat_weekex = sittmaat_weekex[sittmaat_weekex['Q4'] == \"Yes\"]\n",
    "\n",
    "    # Drop the Q4 column\n",
    "    sittmaat_weekex = sittmaat_weekex.drop(columns=['Q4'])\n",
    "\n",
    "\n",
    "    #rename columns\n",
    "    sittmaat_weekex = rename_columns(sittmaat_weekex)\n",
    "\n",
    "    # Convert the DataFrame from wide to long format\n",
    "    sittmaat_weekex_long = pd.melt(sittmaat_weekex, id_vars=['Name', 'Start Date', 'End Date'],\n",
    "                                   value_vars=[col for col in sittmaat_weekex.columns if col.endswith('_mins')],\n",
    "                                   var_name='Activity', value_name='Mins')\n",
    "\n",
    "\n",
    "    # Remove rows with NaN values in the 'Mins' column\n",
    "    sittmaat_weekex_long = sittmaat_weekex_long.dropna(subset=['Mins'])\n",
    "\n",
    "    # Convert 'Mins' to numeric and calculate 'Hrs'\n",
    "    sittmaat_weekex_long['Mins'] = pd.to_numeric(sittmaat_weekex_long['Mins'])\n",
    "    sittmaat_weekex_long['Hrs'] = sittmaat_weekex_long['Mins'] / 60\n",
    "\n",
    "    # Add 'Category' column\n",
    "    sittmaat_weekex_long['Category'] = sittmaat_weekex_long['Activity'].apply(lambda x: \n",
    "        'EMF' if x.startswith('EMF_') else\n",
    "        'NIATxMAT Academy' if x.startswith('NIATxMAT_') else\n",
    "        'Internal Facilitation' if x.startswith('InternalF_') else\n",
    "        'External Facilitation' if x.startswith('ExternalF_') else\n",
    "        'SIC/COINS' if x.startswith('SIC/COINS_') else\n",
    "        'SITMAAT Purveyor Team' if x.startswith('SITMAATTeam_') else\n",
    "        'Additional Relevant Activities' if x.startswith('additionalactivity') else\n",
    "        'Additional Costing Tasks' if x.startswith('additionalcosting_') else\n",
    "        None\n",
    "    )\n",
    "\n",
    "    return sittmaat_weekex_long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02fdb5-40ac-41d6-be29-b2fa27d89f15",
   "metadata": {},
   "source": [
    "## Putting sheets into an excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e1cde00-573d-4586-b66f-c0d0f152dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to export DataFrames to an Excel file with multiple sheets\n",
    "def export_to_excel(file_name, dfs, sheet_names):\n",
    "    full_path = os.path.abspath(file_name)\n",
    "    \n",
    "    # Check if the file already exists and delete it if it does\n",
    "    if os.path.exists(full_path):\n",
    "        os.remove(full_path)\n",
    "    \n",
    "    with xw.App(visible=False) as app:\n",
    "        wb = app.books.add()\n",
    "\n",
    "        for df, sheet_name in zip(dfs, sheet_names):\n",
    "            sheet = wb.sheets.add(sheet_name)\n",
    "            sheet.range('A1').options(index=False).value = df\n",
    "        wb.save(file_name)\n",
    "        wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff662b47-1839-413d-a055-1a1e093061f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The following columns are not renamed and will be dropped: ['StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage', 'Q4']\n"
     ]
    }
   ],
   "source": [
    "involved = clean_involved(df_raw)\n",
    "additional_activities_hours, additional_activities_no_hours = clean_additional_activities(df_raw)\n",
    "not_involved = clean_not_involved(df_raw)\n",
    "optional_notes = clean_optional_notes(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0ed64f9-4c74-40fa-9ddc-98d9b2691b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_notes = optional_notes[optional_notes['Optional Notes'] == optional_notes['Optional Notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a2f6b7d-3222-4ae8-a40f-ebb06f32fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames and corresponding sheet names\n",
    "dfs = [optional_notes, not_involved, additional_activities_hours, additional_activities_no_hours, involved,]\n",
    "sheet_names = [\"Comments\",\"Not Involved\", \"Additional - Hours\", \"Additional - No Hours\", \"Involved\",]\n",
    "\n",
    "# Export to Excel\n",
    "export_to_excel('costing_out/cleaned_data_06102024.xlsx', dfs, sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebbcf0-6bf8-4871-80f7-c6a399c0cf98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## adding onto the summary sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c386978-15f8-4a68-98a4-33779d3cf14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_existing_sheets(file_path):\n",
    "#     existing_data = {}\n",
    "#     wb = xw.Book(file_path)\n",
    "#     sheet_names = [sheet.name for sheet in wb.sheets]\n",
    "#     for sheet_name in sheet_names:\n",
    "#         sheet = wb.sheets[sheet_name]\n",
    "#         existing_data[sheet_name] = sheet.range('A1').options(pd.DataFrame, expand='table').value\n",
    "#     wb.close()\n",
    "#     return existing_data, sheet_names\n",
    "\n",
    "# def append_new_data(existing_data, new_data, sheet_names):\n",
    "#     for sheet, new_df in zip(sheet_names, new_data):\n",
    "#         if sheet in existing_data:\n",
    "#             existing_df = existing_data[sheet]\n",
    "#             if not existing_df.empty:\n",
    "#                 # Check if columns match\n",
    "#                 existing_columns = set(existing_df.columns)\n",
    "#                 new_columns = set(new_df.columns)\n",
    "#                 if existing_columns != new_columns:\n",
    "#                     missing_in_new = existing_columns - new_columns\n",
    "#                     extra_in_new = new_columns - existing_columns\n",
    "#                     print(f\"Column mismatch in sheet '{sheet}':\")\n",
    "#                     if missing_in_new:\n",
    "#                         print(f\"  Missing in new data: {missing_in_new}\")\n",
    "#                     if extra_in_new:\n",
    "#                         print(f\"  Extra in new data: {extra_in_new}\")\n",
    "#                     continue\n",
    "#                 new_df = new_df.reindex(columns=existing_df.columns)\n",
    "#                 updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "#             else:\n",
    "#                 updated_df = new_df\n",
    "#         else:\n",
    "#             updated_df = new_df\n",
    "#         existing_data[sheet] = updated_df\n",
    "#     return existing_data\n",
    "\n",
    "# def export_to_excel(new_file_path, data_dict):\n",
    "#     full_path = os.path.abspath(new_file_path)\n",
    "    \n",
    "#     # Check if the file already exists and delete it if it does\n",
    "#     if os.path.exists(full_path):\n",
    "#         os.remove(full_path)\n",
    "        \n",
    "#     wb = xw.Book()  # Create a new workbook\n",
    "#     for sheet_name, df in reversed(list(data_dict.items())):  # Reverse the order of sheets\n",
    "#         if sheet_name in [sheet.name for sheet in wb.sheets]:\n",
    "#             wb.sheets[sheet_name].clear()\n",
    "#         else:\n",
    "#             wb.sheets.add(sheet_name)\n",
    "#         wb.sheets[sheet_name].range('A1').options(index=False).value = df\n",
    "#     wb.save(new_file_path)\n",
    "#     wb.close()\n",
    "\n",
    "# def rename_sheets(file_path, new_sheet_names):\n",
    "#     wb = xw.Book(file_path)\n",
    "#     existing_sheet_names = [sheet.name for sheet in wb.sheets]\n",
    "#     for old_name, new_name in zip(existing_sheet_names, new_sheet_names):\n",
    "#         wb.sheets[old_name].name = new_name\n",
    "#     wb.save()\n",
    "#     wb.close()\n",
    "\n",
    "# # Function to generate new sheet names with current date\n",
    "# def generate_sheet_names(base_names):\n",
    "#     current_date = datetime.now().strftime(\"%m.%d.%y\")\n",
    "#     new_sheet_names = [f\"{name} ({current_date})\" for name in base_names]\n",
    "#     return new_sheet_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86183e55-ce96-4599-9960-34dc099254c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # List of DataFrames and corresponding sheet names\n",
    "# # new_dfs = [optional_notes, not_involved, additional_activities_hours, additional_activities_no_hours, involved]\n",
    "# new_dfs = [involved, not_involved, additional_activities_hours, additional_activities_no_hours, optional_notes]\n",
    "\n",
    "# base_sheet_names = [\"Involved\", \"Not Involved\", \"Additional- Hours\", \"Additional- No Hours\", \"Comments\"]\n",
    "\n",
    "# # Rename sheets in the existing Excel file\n",
    "# existing_file_path = 'SITTMAT_050624_Summary.xlsx'\n",
    "\n",
    "# # Generate new sheet names with current date\n",
    "# new_sheet_names = generate_sheet_names(base_sheet_names)\n",
    "# rename_sheets(existing_file_path, new_sheet_names)\n",
    "\n",
    "# # Read existing Excel file\n",
    "# existing_data, sheet_names = read_existing_sheets(existing_file_path)\n",
    "\n",
    "# # Append new data to existing data\n",
    "# updated_data = append_new_data(existing_data, new_dfs, sheet_names)\n",
    "\n",
    "# # Export updated data to a new Excel file\n",
    "# new_file_path = '/Users/liachin-purcell/work/sitt-matt/costing/python/SITTMAT_060624_Summary.xlsx'\n",
    "# export_to_excel(new_file_path, updated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc1601-8ede-4ba7-ba0b-fd3012db4699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
